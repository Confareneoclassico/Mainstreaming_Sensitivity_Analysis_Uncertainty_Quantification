{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity Analysis with test functions\n",
    "\n",
    "<!-- AUTHOR: Samuele lo Piano\n",
    "-->\n",
    "**Samuele Lo Piano**, [s.lopiano@gmail.com](mailto:s.lopiano@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython magic\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# plot configuration\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "# import seaborn as sns # sets another style\n",
    "matplotlib.rcParams['lines.linewidth'] = 3\n",
    "fig_width, fig_height = (7.0,5.0)\n",
    "matplotlib.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "\n",
    "# font = {'family' : 'sans-serif',\n",
    "#   'weight' : 'normal',\n",
    "#   'size' : 18.0}\n",
    "# matplotlib.rc('font', **font) # pass in the font dict as kwar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Global sensitivity\n",
    "analysis](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470725184) is an\n",
    "approached aimed at correlating the uncertainty in the output to the uncertainty\n",
    "in the input parameters. When dealing with non-additive models, it outperforms\n",
    "one-variable-at-a-time sensitivity analysis as this latter does not account for\n",
    "high-order interactions among parameters. This results in incorrect apportion of\n",
    "output uncertainty onto input parameters.\n",
    "\n",
    "A statistical property typically used\n",
    "to account for uncertainty is variance, leading to variance-based sensitivity\n",
    "analysis as a largely adopted practice.\n",
    "\n",
    "It may usually happen in models that\n",
    "not all the input-parameters variability equally affects the output variability.\n",
    "Typical trends consist in [Pareto\n",
    "distributions](https://en.wikipedia.org/wiki/Pareto_distribution) having a small\n",
    "share of the input variables responsible for most of the output variance. Yet\n",
    "one may come across other situations with important high-order interactions\n",
    "cutting across (almost) all the input parameters.\n",
    "\n",
    "The seven analytical\n",
    "functions studied in\n",
    "[Kucherenko_et_al_2011](https://www.sciencedirect.com/science/article/pii/S0951832010002437/)\n",
    "have precisely this aim: represent the possible cases one may come across when\n",
    "computing sensitivity indices. Three typical situations are present: A-type\n",
    "functions with not equally important variables, where one can identify a small\n",
    "set of leading variables while the remainder playing the role of complementary\n",
    "variables; B-type functions, having (normally more than one) dominant low-order\n",
    "terms; C-type functions, for which (almost) all of the parameters are important\n",
    "with significant high-order interactions.\n",
    "\n",
    "Plenty of algorithms have been\n",
    "proposed to compute estimators that could adequately account for the above-\n",
    "mentioned sensitivity indices. Exact analytical expressions are available for\n",
    "these analytical functions, hance putting one in the condition to estimate the\n",
    "quality of the assessment performed with these estimators. One can measure the\n",
    "convergence rate and see how quickly an estimator approaches the actual\n",
    "sensitivity indices value by enlarging the sample size.\n",
    "\n",
    "As we shall see in this\n",
    "notebook, the convergence rate is lower for C-type functions over B-type\n",
    "functions and finally A-type function, these latter presenting the quickest\n",
    "convergence. We also compare here the convergence pace of samples based on [Low-\n",
    "discrepancy Sobol sequency](sobol_interactive.ipynb) against standard random\n",
    "numbers. More details in the [dedicated appendix](sobol_interactive.ipynb).\n",
    "\n",
    "## Defining the test functions\n",
    "\n",
    "<div id=\"sec:the_test_functions\"></div>\n",
    "One can find the expression of the seven test functions we will be dealing within this notebook in equation 1 (\"eq:equation 1\": \"(#eq:test_functions)\" below\n",
    "\n",
    "<!--\n",
    "Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A1: f(X) = \\sum_{j=1}^{k} (-1)^j \\, \\prod_{l=1}^{j} x_l \\\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- Equation labels as ordinary links\n",
    "-->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A2: f(X) = \\prod_{j=1}^{k}\n",
    "\\frac{|{4x_j}-2|+{a_j}}{1+{a_j}} \\\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B1: f(X) = \\prod_{j=1}^{k} \\frac{k-{4x_j}}{k-0.5} \\\n",
    "\\label{_auto3} \\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- Equation labels as ordinary links\n",
    "-->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B2: f(X) = \\left(1+\\frac{1}{k}\\right)^k\n",
    "\\prod_{j=1}^{k} \\sqrt{x_j} \\\n",
    "\\label{_auto4} \\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!--\n",
    "Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "B3: f(X) = \\prod_{j=1}^{k} \\frac{|{4x_j}-2|+{b_j}}{1+{b_j}} \\\n",
    "\\label{_auto5} \\tag{5}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- Equation labels as ordinary links\n",
    "-->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C1: f(X) = \\prod_{j=1}^{k}\n",
    "|{4x_j}-2|\\\n",
    "\\label{_auto6} \\tag{6}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<!-- Equation labels as\n",
    "ordinary links -->\n",
    "<div id=\"_auto7\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C2: f(X) = 2^k\n",
    "\\prod_{j=1}^{k} x_j \\\n",
    "\\label{_auto7} \\tag{7}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In our case we\n",
    "will be working with a set of six parameters. The reader may change the pool as\n",
    "s/he pleases along with the dimension of the lists of the *a* and *b*\n",
    "coefficients. The minimal parameter-pool size able to produce a meaningful\n",
    "inference is set at three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6 # k represents the number of parameters inquired\n",
    "\n",
    "# a and b are the constants' vectors used in the G-function expressions\n",
    "a = [0, 0, 6.52, 6.52, 6.52, 6.52]\n",
    "b = [6.52, 6.52, 6.52, 6.52, 6.52, 6.52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *a* list allows to cover the case where one has two leading parameters with\n",
    "the remaining four in the position of complementarity. Conversely, the *b* list\n",
    "represents the case where all the parameters are equally important. In general,\n",
    "the lower the constant !bt a_k !et, the higher the importance of a parameter for\n",
    "the *G functions* A2, B3 and C1 presented in the study. C1 is the most\n",
    "challenging one as all the additive constants are set at 0.\n",
    "\n",
    "The analytical\n",
    "formulae for the values of the sensitivity indices were retrieved from the\n",
    "quoted\n",
    "[kucherenko_2011](https://www.sciencedirect.com/science/article/pii/S0951832010002437/)\n",
    "or\n",
    "[saltelli_annoni_2010](https://www.sciencedirect.com/science/article/pii/S0010465509003087/)\n",
    "(for the functions A1, A2 and B3). The functions analytical values will serve as\n",
    "external referent when testing the estimators convergence pace.\n",
    "\n",
    "A dataframe of\n",
    "low-discrepancy quasi-random numbers in the interval [0,1] of convenient size is\n",
    "then generated by using a specific algorithm, the [Sobol\n",
    "sequence](https://en.wikipedia.org/wiki/Sobol_sequence). The sample size is\n",
    "defined in relation to powers of 2 due to the specific properties of this\n",
    "algorithm.\n",
    "\n",
    "The import of a non-standard module, 'sobol_seq', is required. It\n",
    "can be easily installed by typing `pip install sobol_seq` from your terminal\n",
    "(Linux) or from the anaconda-prompt environment in case you use Anaconda package\n",
    "manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sobol_seq\n",
    "from string import ascii_lowercase\n",
    "from testfunctions import create_dict, functions, AE_dic, AEF_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [l for l in ascii_lowercase]\n",
    "\n",
    "p_sample = []\n",
    "p_sampleR = []\n",
    "p_sample_name = []\n",
    "f_sample = []\n",
    "f_sampleR = []\n",
    "p = 12\n",
    "\n",
    "df = pd.DataFrame(sobol_seq.i4_sobol_generate(2*k, 2**p-4))\n",
    "df2 = pd.DataFrame(np.random.rand(2**p-4,k*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qamples = []\n",
    "qamplesr = []\n",
    "for s in range (2,p):\n",
    "    qamples.append(df.iloc[(-4+2**s):(-4+2**(s+1))].reset_index(drop=True))\n",
    "    qamplesr.append(df2.iloc[(-4+2**s):(-4+2**(s+1))].reset_index(drop=True))\n",
    "\n",
    "    CheckMAE_mean = []\n",
    "    CheckMAER_mean = []\n",
    "    CheckMAEF_mean = []\n",
    "    CheckMAEFR_mean = []\n",
    "\n",
    "    sample_Matrices = []\n",
    "    sample_MatricesR = []\n",
    "    for m in range (0, 2):\n",
    "        sample_Matrices.append(qamples[s-2].T.iloc[int(m*(len(qamples[s-2].columns)/2)):int((m+1)*(len(qamples[s-2].columns)/2))].reset_index(drop=True).T)\n",
    "        sample_MatricesR.append(qamplesr[s-2].T.iloc[int(m*(len(qamplesr[s-2].columns)/2)):int((m+1)*(len(qamplesr[s-2].columns)/2))].reset_index(drop=True).T)\n",
    "\n",
    "    sample_Matrices_dic = create_dict(letters, sample_Matrices)\n",
    "    sample_MatricesR_dic = create_dict(letters, sample_MatricesR)\n",
    "\n",
    "    mixed_Matrices = []\n",
    "    mm_names = []\n",
    "    mixed_MatricesR = []\n",
    "    for sm in range (0,len(sample_Matrices)):\n",
    "        for sm1 in range (0,len(sample_Matrices)):\n",
    "            if sm == sm1:\n",
    "                continue\n",
    "            else:\n",
    "                for c in sample_Matrices[sm]:\n",
    "                    mixed_Matrices.append(sample_Matrices[sm].copy())\n",
    "                    mixed_Matrices[len(mixed_Matrices)-1][c]=sample_Matrices[sm1].copy()[c]\n",
    "                    mm_names.append(str(letters[sm] + letters[sm1] + str(c+1)))\n",
    "                    mixed_MatricesR.append(sample_MatricesR[sm].copy())\n",
    "                    mixed_MatricesR[len(mixed_MatricesR)-1][c]=sample_MatricesR[sm1].copy()[c]\n",
    "\n",
    "    mixed_Matrices_dic = create_dict(mm_names, mixed_Matrices)\n",
    "    mixed_MatricesR_dic = create_dict(mm_names, mixed_MatricesR)\n",
    "\n",
    "    matrices_dic = {**sample_Matrices_dic, **mixed_Matrices_dic}\n",
    "    matricesR_dic = {**sample_MatricesR_dic, **mixed_MatricesR_dic}\n",
    "\n",
    "    names1 = []\n",
    "    values1R = []\n",
    "    values1 = []\n",
    "    names2 = []\n",
    "    values2 = []\n",
    "    values2R = []\n",
    "    for f in functions:\n",
    "        for sq, zq in mixed_Matrices_dic.items():\n",
    "            names1.append(f.__name__+str(sq))\n",
    "            values1.append(f(zq))\n",
    "        for sqR, zqR in mixed_MatricesR_dic.items():\n",
    "            values1R.append(f(zqR))\n",
    "\n",
    "        for sM, zM in matrices_dic.items():\n",
    "            names2.append(f.__name__+str(sM))\n",
    "            values2.append(f(zM))\n",
    "        for sMR, zMR in matricesR_dic.items():\n",
    "            values2R.append(f(zMR))\n",
    "\n",
    "    f_MM_dic = create_dict(names1, values1)\n",
    "    f_matrices_dic = create_dict(names2, values2)\n",
    "    f_MMR_dic = create_dict(names1, values1R)\n",
    "    f_matricesR_dic = create_dict(names2, values2R)\n",
    "\n",
    "    Check=[]\n",
    "    CheckR=[]\n",
    "    CheckName = []\n",
    "    Check3=[]\n",
    "    Check3R=[]\n",
    "    Check3Name = []\n",
    "    for f in functions:\n",
    "        for j in range(1,k+1):\n",
    "            difference = []\n",
    "            difference3 = []\n",
    "            differenceR = []\n",
    "            difference3R = []\n",
    "            for mk, mz in f_matrices_dic.items():\n",
    "                if mk[0:2]==f.__name__:\n",
    "                    validkeys = []\n",
    "                    validkeys3 = []\n",
    "                    for fk1 in f_MM_dic.keys():\n",
    "                        if len(mk)==3 and mk[2]=='a': \n",
    "                            if fk1[0:3]==mk[0:3] and fk1[-1]==str(j):\n",
    "                                validkeys.append(fk1)\n",
    "                            if fk1[0:2]==mk[0:2] and fk1[2]!=mk[2] and fk1[-1]==str(j):\n",
    "                                validkeys3.append(fk1)\n",
    "                    z1 = dict(filter(lambda i:i[0] in validkeys, f_MM_dic.items()))\n",
    "                    z3 = dict(filter(lambda i3:i3[0] in validkeys3, f_MM_dic.items()))\n",
    "                    for zk, zv in z1.items():\n",
    "                        difference.append(0.5*(((mz-zv)**2).mean())/mz.var())\n",
    "                    for zk3, zv3 in z3.items():\n",
    "                        difference3.append(((mz*zv3).mean()-mz.mean()**2)/mz.var())\n",
    "            Check.append(sum(difference)/len(difference))\n",
    "            CheckName.append('Jansen'+ str(f.__name__) +'ST'+str(j))\n",
    "            Check3.append(sum(difference3)/len(difference3))\n",
    "            Check3Name.append('Sobol'+ str(f.__name__) +'S'+str(j))\n",
    "            for mkR, mzR in f_matricesR_dic.items():\n",
    "                if mkR[0:2]==f.__name__:\n",
    "                    validkeysR = []\n",
    "                    validkeys3R = []\n",
    "                    for fk1R in f_MMR_dic.keys():\n",
    "                        if len(mkR)==3 and mkR[2]=='a': \n",
    "                            if fk1R[0:3]==mkR[0:3] and fk1R[-1]==str(j):\n",
    "                                validkeysR.append(fk1R)\n",
    "                            if fk1R[0:2]==mkR[0:2] and fk1R[2]!=mkR[2] and fk1R[-1]==str(j):\n",
    "                                validkeys3R.append(fk1R)\n",
    "                    z1R = dict(filter(lambda iR:iR[0] in validkeysR, f_MMR_dic.items()))\n",
    "                    z3R = dict(filter(lambda iR3:iR3[0] in validkeys3R, f_MMR_dic.items()))\n",
    "                    for zkR, zvR in z1R.items():\n",
    "                        differenceR.append(0.5*(((mzR-zvR)**2).mean())/mzR.var())\n",
    "                    for zk3R, zv3R in z3R.items():\n",
    "                        difference3R.append(((mzR*zv3R).mean()-mzR.mean()**2)/mzR.var()) \n",
    "            CheckR.append(sum(differenceR)/len(differenceR))\n",
    "            Check3R.append(sum(difference3R)/len(difference3R))\n",
    "    Check_dic = create_dict(CheckName, Check)\n",
    "    Check3_dic = create_dict(Check3Name, Check3)\n",
    "    CheckR_dic = create_dict(CheckName, CheckR)\n",
    "    Check3R_dic = create_dict(Check3Name, Check3R)\n",
    "\n",
    "    CheckMAEs = []\n",
    "    CheckMAEsR = []\n",
    "    CheckMAENames = []\n",
    "    CheckMAEsF = []\n",
    "    CheckMAEsFR = []\n",
    "    CheckMAEFNames = []\n",
    "    for ae, av in AE_dic.items():\n",
    "        for Lk, Lv in Check_dic.items():\n",
    "            if ae[-5:]==Lk[-5:]:\n",
    "                CheckMAEs.append(abs(Lv-av))\n",
    "                CheckMAENames.append('CheckMAE'+ str(ae[2:4]) + str(ae[-1]))\n",
    "        for LkR, LvR in CheckR_dic.items():\n",
    "            if ae[-5:]==LkR[-5:]:\n",
    "                CheckMAEsR.append(abs(LvR-av))\n",
    "    for af, afv in AEF_dic.items():\n",
    "        for Lk3, Lv3 in Check3_dic.items():\n",
    "            if af[-4:]==Lk3[-4:]:\n",
    "                CheckMAEsF.append(abs(Lv3-afv))\n",
    "                CheckMAEFNames.append('CheckMAE'+ str(af[2:4]) + str(af[-1]))\n",
    "        for Lk3R, Lv3R in Check3R_dic.items():\n",
    "            if af[-4:]==Lk3R[-4:]:\n",
    "                CheckMAEsFR.append(abs(Lv3R-afv))\n",
    "    CheckMAEs_dic = create_dict(CheckMAENames, CheckMAEs)\n",
    "    CheckMAEsF_dic = create_dict(CheckMAEFNames, CheckMAEsF)\n",
    "    CheckMAEsR_dic = create_dict(CheckMAENames, CheckMAEsR)\n",
    "    CheckMAEsFR_dic = create_dict(CheckMAEFNames, CheckMAEsFR)\n",
    "\n",
    "    CheckMAE = []\n",
    "    CheckMAER = []\n",
    "    CheckMAE_name = []\n",
    "    CheckMAEF = []\n",
    "    CheckMAEFR = []\n",
    "    for f in functions:\n",
    "        validkeys2 = []\n",
    "        validkeys4 = []\n",
    "        validkeys2R = []\n",
    "        validkeys4R = []\n",
    "        for Lmk, Lmv in CheckMAEs_dic.items():\n",
    "            if Lmk[-3:-1]==f.__name__:\n",
    "                 validkeys2.append(Lmk)\n",
    "        for Fmk, Fmv in CheckMAEsF_dic.items():\n",
    "            if Fmk[-3:-1]==f.__name__:\n",
    "                 validkeys4.append(Fmk)\n",
    "        z2 = dict(filter(lambda i2:i2[0] in validkeys2, CheckMAEs_dic.items()))\n",
    "        z4 = dict(filter(lambda i4:i4[0] in validkeys4, CheckMAEsF_dic.items()))\n",
    "        CheckMAE.append(sum(z2.values())/len(z2))\n",
    "        CheckMAE_name.append('CheckMAE'+f.__name__)\n",
    "        CheckMAEF.append(sum(z4.values())/len(z4))\n",
    "        for LmkR, LmvR in CheckMAEsR_dic.items():\n",
    "            if LmkR[-3:-1]==f.__name__:\n",
    "                validkeys2R.append(LmkR)\n",
    "        for FmkR, FmvR in CheckMAEsFR_dic.items():\n",
    "            if FmkR[-3:-1]==f.__name__:\n",
    "                 validkeys4R.append(FmkR)\n",
    "        z2R = dict(filter(lambda i2R:i2R[0] in validkeys2R, CheckMAEsR_dic.items()))\n",
    "        z4R = dict(filter(lambda i4R:i4R[0] in validkeys4R, CheckMAEsFR_dic.items()))\n",
    "        CheckMAER.append(sum(z2R.values())/len(z2R))\n",
    "        CheckMAEFR.append(sum(z4R.values())/len(z4R))\n",
    "    CheckMAE_dic = create_dict(CheckMAE_name, CheckMAE)\n",
    "    CheckMAEF_dic = create_dict(CheckMAE_name, CheckMAEF)\n",
    "    CheckMAER_dic = create_dict(CheckMAE_name, CheckMAER)\n",
    "    CheckMAEFR_dic = create_dict(CheckMAE_name, CheckMAEFR)\n",
    "    CheckMAE_mean.append(CheckMAE_dic)\n",
    "    CheckMAER_mean.append(CheckMAER_dic)\n",
    "    CheckMAEF_mean.append(CheckMAEF_dic)\n",
    "    CheckMAEFR_mean.append(CheckMAEFR_dic)\n",
    "    CheckMAE_mean_dic = {Lmk1:[CheckMAE_mean[Lmv1][Lmk1] for Lmv1 in range(len(CheckMAE_mean))] for Lmk1 in CheckMAE_mean[0].keys()}\n",
    "    CheckMAER_mean_dic = {Lmk2:[CheckMAER_mean[Lmv2][Lmk2] for Lmv2 in range(len(CheckMAER_mean))] for Lmk2 in CheckMAER_mean[0].keys()}\n",
    "    CheckMAEF_mean_dic = {Lmk3:[CheckMAEF_mean[Lmv3][Lmk3] for Lmv3 in range(len(CheckMAEF_mean))] for Lmk3 in CheckMAEF_mean[0].keys()}\n",
    "    CheckMAEFR_mean_dic = {Lmk4:[CheckMAEFR_mean[Lmv4][Lmk4] for Lmv4 in range(len(CheckMAEFR_mean))] for Lmk4 in CheckMAEFR_mean[0].keys()}\n",
    "    for Lmk1,Lmv1 in CheckMAE_mean_dic.items():\n",
    "        CheckMAE_mean_dic[Lmk1] = sum(CheckMAE_mean_dic[Lmk1])/len(CheckMAE_mean_dic[Lmk1])\n",
    "    for Lmk2,Lmv2 in CheckMAER_mean_dic.items():\n",
    "        CheckMAER_mean_dic[Lmk2] = sum(CheckMAER_mean_dic[Lmk2])/len(CheckMAER_mean_dic[Lmk2])\n",
    "    for Lmk3,Lmv3 in CheckMAEF_mean_dic.items():\n",
    "        CheckMAEF_mean_dic[Lmk3] = sum(CheckMAEF_mean_dic[Lmk3])/len(CheckMAEF_mean_dic[Lmk3])\n",
    "    for Lmk4,Lmv4 in CheckMAEFR_mean_dic.items():\n",
    "        CheckMAEFR_mean_dic[Lmk4] = sum(CheckMAEFR_mean_dic[Lmk4])/len(CheckMAEFR_mean_dic[Lmk4])\n",
    "\n",
    "    p_sample.append(CheckMAE_mean_dic)\n",
    "    p_sample_name.append(2**s)\n",
    "    f_sample.append(CheckMAER_mean_dic)\n",
    "    p_sampleR.append(CheckMAEF_mean_dic)\n",
    "    f_sampleR.append(CheckMAEFR_mean_dic)\n",
    "    p_sample_dic = create_dict(p_sample_name, p_sample)\n",
    "    f_sample_dic = create_dict(p_sample_name, f_sample)\n",
    "    p_sampleR_dic = create_dict(p_sample_name, p_sampleR)\n",
    "    f_sampleR_dic = create_dict(p_sample_name, f_sampleR)\n",
    "\n",
    "Checkq = pd.DataFrame.from_dict(p_sample_dic)\n",
    "Checkf = pd.DataFrame.from_dict(f_sample_dic)\n",
    "CheckR = pd.DataFrame.from_dict(p_sampleR_dic)\n",
    "CheckfR = pd.DataFrame.from_dict(f_sampleR_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobol matrix gets sliced in a way that every sample is twice bigger than the\n",
    "previous `qamples` list elements. The first one has only two rows. From\n",
    "iteration to iteration the number gets increased as 2 to the power of s, up to\n",
    "2,048 rows for the last one. The `qamples` matrix gets in turn sliced in 50\n",
    "parts of equivalent size. The rationale behind this operation is generating an\n",
    "adequate numbers of runs whose output can be averaged to compensate for\n",
    "fluctuations.\n",
    "\n",
    "Two sample matrices are generated by slicing down the larger\n",
    "matrix in two parts of equal length. The code line `sample_Matrices_dic` creates\n",
    "a dictionary by appending the name to the matrices in the order they have been\n",
    "generated (a, b). This operation can be ideally replicated in the case one\n",
    "wishes to compute more sample matrices for the estimators algorithm.\n",
    "\n",
    "The mixed\n",
    "matrices (i.e. ab1, ab6, ba2, etc.) are generated by scrambling the columns of\n",
    "the sample matrices. The first *if* excludes counting the same matrix twice, the\n",
    "second lower level *for* loop replicates the matrices the number of parameters\n",
    "one has and for each scrambles the relative column. Finally, the name is\n",
    "appended dependent the original matrix, the matrix whose column has been used\n",
    "for the scrambling and the number of the column. The label is eventually\n",
    "associated to the mixed matrices in the same way as done for the sample\n",
    "matrices. The sample and mixed matrices are zipped together into a\n",
    "`matrices_dic`.\n",
    "\n",
    "The functions are applied to the sets of matrices and the\n",
    "result of the operations are stored into dictionaries again. Now each item in\n",
    "the dictionaries `f_MM_dic` and `f_matrices_dic` is a vector rather than a\n",
    "matrix (f(a), f(b), f(ab4), etc.)\n",
    "\n",
    "For each function, the sample matrices are\n",
    "selected ('if len(mk)==3:'). From the ensemble of the scramble matrices, those\n",
    "having the same function and starting letter are selected for the total\n",
    "sensivity index accounting. While a different starting letter is the condition\n",
    "for the first-order estimator (fk1[2]!=mk[2]). The selection is based on the\n",
    "names (keys). The dictionary is filtered according to these criteria and the\n",
    "Jansen estimator-to-variance ratio is computed for the higher order (`Check` and\n",
    "`CheckR`) and the Sobol estimator-to-variance ratio for the first order matrices\n",
    "(`Check3` and `Check3R`).\n",
    "\n",
    "Finally, the Mean Absolute Errors, the difference\n",
    "between the analytical value and the estimator figure, are computed and the\n",
    "values appended in a dictionary.\n",
    "\n",
    "These figures are then averaged on the\n",
    "different parameters (from six figures to one) as well as runs and stored in a\n",
    "dictionary `CheckMAE_dic` and `CheckMAEF_dic`.\n",
    "\n",
    "Which is in turn appended onto\n",
    "the final dictionary wrapping up all the experiments performed (up to the power\n",
    "of 2 'p' initially defined). This latter is eventually converted into a\n",
    "convenient *pandas* dataframe from which the trends can be easily plotted or\n",
    "statistically inference on the figures can be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in Checkq.iterrows():\n",
    " for indR, row in CheckR.iterrows():\n",
    "  if ind == indR:\n",
    "   x_vals = Checkq.columns.values\n",
    "   y1 = Checkq.loc[ind]\n",
    "   y2 = CheckR.loc[indR]\n",
    "   for i6 in range(0, len(x_vals), 1):\n",
    "    plt.loglog(x_vals[i6:i6+2], y1[i6:i6+2], c = \"b\", marker = \"o\", label = 'QR' if i6 == 0 else '')\n",
    "    plt.loglog(x_vals[i6:i6+2], y2[i6:i6+2], c = \"r\", marker = \"x\", label ='R' if i6 == 0 else '')\n",
    "    plt.xlim(0,8500)\n",
    "   plt.title('Jansen' + '_ST_' +str(ind[-2:]))\n",
    "   plt.legend()\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of plots is finally produced whose trend is compared against the sample\n",
    "size across functions in order to evaluate the convergence rate of the higher-\n",
    "order sensitivity indices. The convergence paces appear to be slower for C-type\n",
    "functions. For these latter, the convergence pace of Quasi-random-based\n",
    "functions against random-based functions appears to be similar and there would\n",
    "be no advantage in using a low-discrepancy sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in Checkf.iterrows():\n",
    " for indR, row in CheckfR.iterrows():\n",
    "  if ind == indR:\n",
    "   x_vals = Checkf.columns.values\n",
    "   y1 = Checkf.loc[ind]\n",
    "   y2 = CheckfR.loc[indR]\n",
    "   for i6 in range(0, len(x_vals), 1):\n",
    "    plt.loglog(x_vals[i6:i6+2], y1[i6:i6+2], c = \"b\", marker = \"o\", label = 'QR' if i6 == 0 else '')\n",
    "    plt.loglog(x_vals[i6:i6+2], y2[i6:i6+2], c = \"r\", marker = \"x\", label ='R' if i6 == 0 else '')\n",
    "    plt.xlim(0,8500)\n",
    "   plt.title('Sobol' + '_S_' +str(ind[-2:]))\n",
    "   plt.legend()\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same operation can be repeated for first-order indices. The inference on the\n",
    "trends is analogous to high-order indices.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "The convergence pace\n",
    "is an aspect an analyst should have clear in mind when designing the experiment\n",
    "to account for the sensitivity indices: complicated models with plenty of\n",
    "relevant higher-order interactions would call for larger sample sizes and\n",
    "therefore longer and more computational demanding experiments to adequately\n",
    "estimate the sensitivity indices. Low-discrepancy sequences can play a role in\n",
    "easing the correct computation of sensitivity indices as long as high-order\n",
    "terms are not dominant for most of the input parameters."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
